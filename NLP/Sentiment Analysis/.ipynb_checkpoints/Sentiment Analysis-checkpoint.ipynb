{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "The goal of this notebook is to scrap an API endpoint for regenerative ag data and present it in an interactive plot to deploy in a dashboard which can be shared via link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Get data from reddit regarding regenerative agriculture\n",
    "2. Analyze data with plotly \n",
    "3. Top Comments over the past week\n",
    "4. Sentiment over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from reddit regenerative agriculture (or any other) keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get info \n",
    "def get_pushshift_data(data_type, **kwargs):\n",
    "    \"\"\" \n",
    "    Gets data from the pushshift api.\n",
    "    data_type can be 'comment' or 'submission'\n",
    "    other args are interpreted as payload.\n",
    "    Read more: https://github.com/pushshift/api\n",
    "    \"\"\"\n",
    "    base_url = f\"https://api.pushshift.io/reddit/search/{data_type}/\"\n",
    "    payload = kwargs\n",
    "    request = requests.get(base_url, params=payload)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use example\n",
    "get_pushshift_data(data_type=\"comment\",           # give me comments\n",
    "                   q=\"python\",                    # that mention 'python'\n",
    "                   after=\"1y\",                    # in the last year\n",
    "                   size=1000,                     # maximum 1000 comments\n",
    "                   sort_type=\"score\",             # sort them by score\n",
    "                   sort=\"desc\",                   # sort descending\n",
    "                   aggs=\"subreddit\")              # groups result by subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data with plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages for this step\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-a0a9730ce3c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m data = get_pushshift_data(data_type=\"comment\",\n\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"python\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0mafter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"48h\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           aggs=\"subreddit\")\n",
      "\u001b[1;32m<ipython-input-39-a18c4279fd3c>\u001b[0m in \u001b[0;36mget_pushshift_data\u001b[1;34m(data_type, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpayload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "data = get_pushshift_data(data_type=\"comment\",\n",
    "                          q=\"python\",\n",
    "                          after=\"48h\",\n",
    "                          size=1000,\n",
    "                          aggs=\"subreddit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.get(\"aggs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-ade0c79ee3a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# dig through the json nesting and then return as pandas df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aggs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"subreddit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# dig through the json nesting and then return as pandas df\n",
    "data = data.get(\"aggs\").get(\"subreddit\")\n",
    "df = pd.DataFrame.from_records(data)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_radical</td>\n",
       "      <td>WTF</td>\n",
       "      <td>222</td>\n",
       "      <td>I've never had issues with one. Very rarely do...</td>\n",
       "      <td>https://reddit.com/r/WTF/comments/knf08f/golia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ballasted_orchestra</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td>74</td>\n",
       "      <td>I'm so tired of seeing all of these extremely ...</td>\n",
       "      <td>https://reddit.com/r/interestingasfuck/comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William_Harzia</td>\n",
       "      <td>anime_titties</td>\n",
       "      <td>72</td>\n",
       "      <td>So? The benefit of organic meat is supposed to...</td>\n",
       "      <td>https://reddit.com/r/anime_titties/comments/kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yumu22</td>\n",
       "      <td>TrueCrimePodcasts</td>\n",
       "      <td>62</td>\n",
       "      <td>Speaking from what I’ve witnessed, many people...</td>\n",
       "      <td>https://reddit.com/r/TrueCrimePodcasts/comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trollercoaster101</td>\n",
       "      <td>spaceporn</td>\n",
       "      <td>50</td>\n",
       "      <td>It’s amazing how Jean Pierre Luminet obtained ...</td>\n",
       "      <td>https://reddit.com/r/spaceporn/comments/kqhddp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author          subreddit  score  \\\n",
       "0            R_radical                WTF    222   \n",
       "1  ballasted_orchestra  interestingasfuck     74   \n",
       "2       William_Harzia      anime_titties     72   \n",
       "3               yumu22  TrueCrimePodcasts     62   \n",
       "4    Trollercoaster101          spaceporn     50   \n",
       "\n",
       "                                                body  \\\n",
       "0  I've never had issues with one. Very rarely do...   \n",
       "1  I'm so tired of seeing all of these extremely ...   \n",
       "2  So? The benefit of organic meat is supposed to...   \n",
       "3  Speaking from what I’ve witnessed, many people...   \n",
       "4  It’s amazing how Jean Pierre Luminet obtained ...   \n",
       "\n",
       "                                           permalink  \n",
       "0  https://reddit.com/r/WTF/comments/knf08f/golia...  \n",
       "1  https://reddit.com/r/interestingasfuck/comment...  \n",
       "2  https://reddit.com/r/anime_titties/comments/kn...  \n",
       "3  https://reddit.com/r/TrueCrimePodcasts/comment...  \n",
       "4  https://reddit.com/r/spaceporn/comments/kqhddp...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['author', 'subreddit', 'score', 'body', 'permalink'] but received: key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-e6f9d657402c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make plot with plotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m px.bar(df,              # our dataframe\n\u001b[0m\u001b[0;32m      3\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"key\"\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[1;31m# x will be the 'key' column of the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"doc_count\"\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m# y will be the 'doc_count' column of the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Subreddits with 'Regenerative Agriculture' activity over past year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_chart_types.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(data_frame, x, y, color, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, text, base, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, opacity, orientation, barmode, log_x, log_y, range_x, range_y, title, template, width, height)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[0mmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m     return make_figure(\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mconstructor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   1829\u001b[0m     \u001b[0mapply_default_cascade\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1831\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1832\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreemap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSunburst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"path\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_dataframe_hierarchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, constructor)\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m     df_output, wide_id_vars = process_args_into_dataframe(\n\u001b[0m\u001b[0;32m   1364\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwide_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36mprocess_args_into_dataframe\u001b[1;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[0;32m   1164\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0margument\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n To use the index, pass it in directly as `df.index`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margument\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                     raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['author', 'subreddit', 'score', 'body', 'permalink'] but received: key"
     ]
    }
   ],
   "source": [
    "# make plot with plotly\n",
    "px.bar(df,              # our dataframe\n",
    "       x=\"key\",         # x will be the 'key' column of the dataframe\n",
    "       y=\"doc_count\",   # y will be the 'doc_count' column of the dataframe\n",
    "       title=f\"Subreddits with 'Regenerative Agriculture' activity over past year\",\n",
    "       labels={\"doc_count\": \"# comments\",\"key\": \"Subreddits\"}, # the axis names\n",
    "       color_discrete_sequence=[\"blueviolet\"], # the colors used\n",
    "       height=500,\n",
    "       width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Comments Over the past week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >author</th>        <th class=\"col_heading level0 col1\" >subreddit</th>        <th class=\"col_heading level0 col2\" >score</th>        <th class=\"col_heading level0 col3\" >body</th>        <th class=\"col_heading level0 col4\" >permalink</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow0_col0\" class=\"data row0 col0\" >R_radical</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow0_col1\" class=\"data row0 col1\" >WTF</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow0_col2\" class=\"data row0 col2\" >222</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow0_col3\" class=\"data row0 col3\" >I've never had issues with one. Very rarely does sea life of any kind mess with divers unless people are feeding things in that area (which has caused me *serious* issues). Usually the sound of the regs and the bubbles keep just about everything at bay.\n",
       "\n",
       "Please, do not feed the fish. The only time it is acceptable to feed the fish is if you need to evacuate your gut. No food should go overboard ev...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow0_col4\" class=\"data row0 col4\" ><a href=\"https://reddit.com/r/WTF/comments/knf08f/goliath_grouper_eats_shark_whole/ghk9y62/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow1_col0\" class=\"data row1 col0\" >ballasted_orchestra</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow1_col1\" class=\"data row1 col1\" >interestingasfuck</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow1_col2\" class=\"data row1 col2\" >74</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow1_col3\" class=\"data row1 col3\" >I'm so tired of seeing all of these extremely heavily edited nature photos presented as something natural. I don't want to tell anyone what they can and can't do with their art, but it's often presented as something organic. And I understand that a lot of this time this is the OPs fault and not the photographer.\n",
       "\n",
       "I just think it's lying. I'm also tired of people not crediting the photographers. Yo...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow1_col4\" class=\"data row1 col4\" ><a href=\"https://reddit.com/r/interestingasfuck/comments/kmsl86/the_movement_of_the_trees_this_photographer_was/ghgk37b/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow2_col0\" class=\"data row2 col0\" >William_Harzia</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow2_col1\" class=\"data row2 col1\" >anime_titties</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow2_col2\" class=\"data row2 col2\" >72</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow2_col3\" class=\"data row2 col3\" >So? The benefit of organic meat is supposed to be the lack of chemicals and hormones used in the production. Who thought beef produced in a less efficient manner would contribute less to greenhouse gases?\n",
       "\n",
       "This sounds like an industry smear. Honestly OP why did you even post this?...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow2_col4\" class=\"data row2 col4\" ><a href=\"https://reddit.com/r/anime_titties/comments/knjrfk/organic_meats_found_to_have_approximately_the/ghl15oi/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow3_col0\" class=\"data row3 col0\" >yumu22</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow3_col1\" class=\"data row3 col1\" >TrueCrimePodcasts</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow3_col2\" class=\"data row3 col2\" >62</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow3_col3\" class=\"data row3 col3\" >Speaking from what I’ve witnessed, many people’s opinion went way down after the whole plagiarism scandal. As well, the interaction seems a bit fake/ non organic. For example, ways in which Brit responds. It still remains a top podcast, besides all of this, though....</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow3_col4\" class=\"data row3 col4\" ><a href=\"https://reddit.com/r/TrueCrimePodcasts/comments/kqjj80/what_are_your_opinions_on_crime_junkie/gi45s68/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow4_col0\" class=\"data row4 col0\" >Trollercoaster101</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow4_col1\" class=\"data row4 col1\" >spaceporn</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow4_col2\" class=\"data row4 col2\" >50</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow4_col3\" class=\"data row4 col3\" >It’s amazing how Jean Pierre Luminet obtained such an accurate black-hole simulation in 1978.\n",
       "\n",
       "He did all the calculations through a punch card computer and then drew the results dot by dot with india ink. \n",
       "\n",
       "He has an [amazing blog](https://blogs.futura-sciences.com/e-luminet/2018/03/07/45-years-black-hole-imaging-1-early-work-1972-1988/) were the process is described in detail, here is an excerpt...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow4_col4\" class=\"data row4 col4\" ><a href=\"https://reddit.com/r/spaceporn/comments/kqhddp/first_image_of_a_black_hole/gi40um3/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow5_col0\" class=\"data row5 col0\" >Redacted_G1iTcH</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow5_col1\" class=\"data row5 col1\" >AskReddit</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow5_col2\" class=\"data row5 col2\" >48</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow5_col3\" class=\"data row5 col3\" >A tree branch. \n",
       "\n",
       "Diamond and most precious metals are not as rare as we think in the galaxy, but something organic that came from a life form is far rarer. Especially from earth, where the life is allegedly unique to other life forms in the universe...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow5_col4\" class=\"data row5 col4\" ><a href=\"https://reddit.com/r/AskReddit/comments/kqmh32/what_would_you_give_the_aliens_as_a_welcome_to/gi4p7gn/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow6_col0\" class=\"data row6 col0\" >HORAMAN76</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow6_col1\" class=\"data row6 col1\" >Cringetopia</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow6_col2\" class=\"data row6 col2\" >38</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow6_col3\" class=\"data row6 col3\" >I only eat organic salmon...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow6_col4\" class=\"data row6 col4\" ><a href=\"https://reddit.com/r/Cringetopia/comments/kn8j3a/youtube_really_put_a_child_groomer_on_trending/ghk299f/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow7_col0\" class=\"data row7 col0\" >j_slosh</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow7_col1\" class=\"data row7 col1\" >houseplants</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow7_col2\" class=\"data row7 col2\" >36</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow7_col3\" class=\"data row7 col3\" >More or less, the plant eats it as it breaks down. Dirt is organic matter that’s breaks down over time, mostly it’s poop from worms, insects, and also bacteria and fungi. The roots use it up as your watering breaks it down. Plus some is flushed out of drainage holes...</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow7_col4\" class=\"data row7 col4\" ><a href=\"https://reddit.com/r/houseplants/comments/kq0aa0/where_does_all_the_dirt_go/gi15jk3/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow8_col0\" class=\"data row8 col0\" >cayshek</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow8_col1\" class=\"data row8 col1\" >AliandJohnJames</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow8_col2\" class=\"data row8 col2\" >32</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow8_col3\" class=\"data row8 col3\" >“qUaLiTy TiMe” after we all called her out for saying CPS said Emmy was fine because she was eating organic eggs and custom clothes instead of talking about playing with her/reading to her eat....</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow8_col4\" class=\"data row8 col4\" ><a href=\"https://reddit.com/r/AliandJohnJames/comments/kmswxp/hahahaha_no_she_did_not/ghgj33u/\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96dlevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow9_col0\" class=\"data row9 col0\" >Rambo7112</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow9_col1\" class=\"data row9 col1\" >AskReddit</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow9_col2\" class=\"data row9 col2\" >31</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow9_col3\" class=\"data row9 col3\" >Acetic acid does not replace insulin, and natural does not mean good. \n",
       "\n",
       "Being a chem major is really fun when people try to convince you of stuff by using the words, \"chemicals\", \"organic\" and \"natural.\" If anything, \"organic\" scares me away from the product....</td>\n",
       "                        <td id=\"T_8118c11c_4fa1_11eb_ac50_fcaa1475b96drow9_col4\" class=\"data row9 col4\" ><a href=\"https://reddit.com/r/AskReddit/comments/kmkfow/whats_the_stupidest_thing_someone_has_said_to_you/ghg2rra/\">Link</a></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a40c70a610>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top comment data with function\n",
    "data = get_pushshift_data(data_type=\"comment\", \n",
    "                          q=\"organic\", \n",
    "                          after=\"7d\", \n",
    "                          size=10, \n",
    "                          sort_type=\"score\", \n",
    "                          sort=\"desc\").get(\"data\")\n",
    "\n",
    "# put columns of interest in df\n",
    "df = pd.DataFrame.from_records(data)[[\"author\", \"subreddit\", \"score\", \"body\", \"permalink\"]]\n",
    "\n",
    "# limit body of the comment\n",
    "df['body'] = df['body'].str[0:400] + \"...\"\n",
    "\n",
    "# append the string to all the permalink entries so that there's a link to the comment\n",
    "df['permalink'] = \"https://reddit.com\" + df['permalink'].astype(str)\n",
    "\n",
    "# function for making clickable links in df table\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">Link</a>'.format(val,val)\n",
    "\n",
    "# style the last column to be clickable and print\n",
    "df.style.format({'permalink': make_clickable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data of interest with function\n",
    "data = get_pushshift_data(data_type=\"comment\",\n",
    "                          after=\"2d\",\n",
    "                          size=1000,\n",
    "                          sort_type=\"score\",\n",
    "                          sort=\"desc\",\n",
    "                          subreddit=\"python\").get(\"data\")\n",
    "\n",
    "# define columns of interest\n",
    "columns_of_interest = [\"author\", \"body\", \"created_utc\", \"score\", \"permalink\"]\n",
    "\n",
    "# transform the response into a dataframe with relevant columns\n",
    "df = pd.DataFrame.from_records(data)[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column with sentiment polarity\n",
    "df[\"sentiment_polarity\"] = df.apply(lambda row: textblob.TextBlob(row[\"body\"]).sentiment.polarity, axis=1)\n",
    "\n",
    "# create a column with sentiment subjectivity\n",
    "df[\"sentiment_subjectivity\"] = df.apply(lambda row: textblob.TextBlob(row[\"body\"]).sentiment.subjectivity, axis=1)\n",
    "\n",
    "# create a column with 'positive' or 'negative' depending on sentiment_polarity\n",
    "df[\"sentiment\"] = df.apply(lambda row: \"positive\" if row[\"sentiment_polarity\"] >= 0 else \"negative\", axis=1)\n",
    "\n",
    "# create a column with a text preview that shows the first 50 characters\n",
    "df[\"preview\"] = df[\"body\"].str[0:50]\n",
    "\n",
    "# take the created_utc parameter and tranform it into a datetime column\n",
    "df[\"date\"] = pd.to_datetime(df['created_utc'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make visual with plotly\n",
    "px.scatter(df, x=\"date\", # date on the x axis\n",
    "               y=\"sentiment_polarity\", # sentiment on the y axis\n",
    "               hover_data=[\"author\", \"permalink\", \"preview\"], # data to show on hover\n",
    "               color_discrete_sequence=[\"lightseagreen\", \"indianred\"], # colors to use\n",
    "               color=\"sentiment\", # what should the color depend on?\n",
    "               size=\"score\", # the more votes, the bigger the circle\n",
    "               size_max=10, # not too big\n",
    "               labels={\"sentiment_polarity\": \"Comment positivity\", \"date\": \"Date comment was posted\"}, # axis names\n",
    "               title=f\"Comment sentiment in /r/python for the past 48h\", # title of figure\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
